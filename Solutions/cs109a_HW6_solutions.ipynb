{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/STAT 121A/AC 209A/CSCI E-109A: Homework 6\n",
    "# Reg-Logistic Regression, ROC, and Data Imputation\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2017**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, Rahul Dave, Margo Levine\n",
    "\n",
    "---\n",
    "\n",
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- Do not include your name(s) in the notebook if you are submitting as a group. \n",
    "- If you submit individually and you have worked with someone, please include the name of your [one] partner below. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your partner's name (if you submit separately):\n",
    "\n",
    "Enrollment Status (109A, 121A, 209A, or E109A):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Breast Cancer Detection\n",
    "\n",
    "In this homework, we will consider the problem of early breast cancer detection from X-ray images. Specifically, given a candidate region of interest (ROI) from an X-ray image of a patient's breast, the goal is to predict if the region corresponds to a malignant tumor (label 1) or is normal (label 0). The training and test data sets for this problem is provided in the file `hw6_dataset.csv`. Each row in these files corresponds to a ROI in a patient's X-ray, with columns 1-117 containing features computed using standard image processing algorithms. The last column contains the class label, and is based on a radiologist's opinion or a biopsy. This data was obtained from the KDD Cup 2008 challenge.\n",
    "\n",
    "The data set contain a total of 102,294 candidate ROIs, of which only 623 are malignant, while the remaining are all normal. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Beyond Classification Accuracy\n",
    "\n",
    "\n",
    "0.  Split the data set into a training set and a testing set.  The training set should be 75% of the original data set, and the testing set 25%.  Use `np.random.seed(9001)`.\n",
    "\n",
    "1. Fit a logistic regression classifier to the training set and report the  accuracy of the classifier on the test set. You should use $L_2$ regularization in logistic regression, with the regularization parameter tuned using cross-validation. \n",
    "    1. How does the fitted model compare with a classifier that predicts 'normal' (label 0) on all patients? \n",
    "    2. Do you think the difference in the classification accuracies are large enough to declare logistic regression as a better classifier than the all 0's classifier? Why or why not?\n",
    "    \n",
    "For applications with imbalanced class labels, in this case when there are many more healthy subjects ($Y=0$) than those with cancer ($Y=1$), the classification accuracy may not be the best metric to evaluate a classifier's performance. As an alternative, we could analyze the confusion table for the classifier. \n",
    "\n",
    "<ol start=\"3\">\n",
    "<li> Compute the confusion table for both the fitted classifier and the classifier that predicts all 0's.</li>\n",
    "<li> Using the entries of the confusion table compute the *true positive rate* and the *true negative rate* for the two classifiers. Explain what these evaluation metrics mean for the specific task of cancer detection. Based on the observed metrics, comment on whether the fitted model is better than the all 0's classifier.</li>\n",
    "<li> What is the *false positive rate* of the fitted classifier, and how is it related to its true positive and true negative rate? Why is a classifier with high false positive rate undesirable for a cancer detection task?</li>\n",
    "</ol>\n",
    "*Hint:* You may use the `metrics.confusion_matrix` function to compute the confusion matrix for a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 Solutions:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1\\. Split the data set into a training set and a testing set.  The training set should be 75% of the original data set, and the testing set 25%.  Use `np.random.seed(9001)`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('HW6_dataset.csv', header=0, names=list(range(1,118)) + ['type'])\n",
    "\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(df)) < 0.75\n",
    "data_train = df[msk]\n",
    "data_test = df[~msk]\n",
    "\n",
    "X_train = data_train.loc[:, data_train.columns != 'type']\n",
    "y_train = data_train['type']\n",
    "X_test = data_test.loc[:, data_test.columns != 'type']\n",
    "y_test = data_test['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2\\. Fit a logistic regression classifier to the training set and report the  accuracy of the classifier on the test set. You should use $L_2$ regularization in logistic regression, with the regularization parameter tuned using cross-validation.**\n",
    "    1. How does the fitted model compare with a classifier that predicts 'normal' (label 0) on all patients?\n",
    "    2. Do you think the difference in the classification accuracies are large enough to declare logistic regression as a better classifier than the all 0's classifier? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.995462323829\n",
      "Test accuracy:  0.995084269663\n"
     ]
    }
   ],
   "source": [
    "logregcv = LogisticRegressionCV(random_state = 123) # By default LBGFS induces L2 norm.\n",
    "logregcv.fit(X_train, y_train)\n",
    "y_hat_train = logregcv.predict(X_train)\n",
    "y_hat_test = logregcv.predict(X_test)\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.994135630372\n",
      "Test accuracy:  0.993913857678\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", accuracy_score(y_train, [0 for y in y_train]))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, [0 for y in y_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted model does barely better than on a model that predicts normal on all patients, so no. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3\\. Compute the confusion table for both the fitted classifier and the classifier that predicts all 0's.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat=0</th>\n",
       "      <th>y_hat = 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y=0</th>\n",
       "      <td>16976</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y=1</th>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_hat=0  y_hat = 1\n",
       "y=0    16976          8\n",
       "y=1       76         28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat = confusion_matrix(y_test, y_hat_test)\n",
    "conf_df = pd.DataFrame(conf_mat, columns = ['y_hat=0', 'y_hat = 1'], index = ['y=0', 'y=1'])\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat=0</th>\n",
       "      <th>y_hat = 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y=0</th>\n",
       "      <td>16984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y=1</th>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_hat=0  y_hat = 1\n",
       "y=0    16984          0\n",
       "y=1      104          0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_naive = confusion_matrix(y_test, [0 for y in y_test])\n",
    "conf_df_naive = pd.DataFrame(conf_mat_naive, columns = ['y_hat=0', 'y_hat = 1'], index = ['y=0', 'y=1'])\n",
    "conf_df_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**4\\. Using the entries of the confusion table compute the *true positive rate* and the *true negative rate* for the two classifiers. Explain what these evaluation metrics mean for the specific task of cancer detection. Based on the observed metrics, comment on whether the fitted model is better than the all 0's classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate for Fitted:  0.269230769231\n",
      "True Negative Rate for Fitted:  0.999528968441\n"
     ]
    }
   ],
   "source": [
    "print(\"True Positive Rate for Fitted: \", float(conf_mat[1][1])/(conf_mat[1][1]+ conf_mat[1][0]))\n",
    "print(\"True Negative Rate for Fitted: \", float(conf_mat[0][0])/(conf_mat[0][0] + conf_mat[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate for Naive:  0.0\n",
      "True Negative Rate for Naive:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"True Positive Rate for Naive: \", float(conf_mat_naive[1][1])/(conf_mat_naive[1][1]+ conf_mat_naive[1][0]))\n",
    "print(\"True Negative Rate for Naive: \", float(conf_mat_naive[0][0])/(conf_mat_naive[0][0] + conf_mat_naive[0][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ones with all zeros, we never get any false positives. However, the number of false negatives increase, which is fundamentally bad as that means there are people with cancer who are told they do not, and hence they may not seek proper treatment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**5\\. What is the *false positive rate* of the fitted classifier, and how is it related to its true positive and true negative rate? Why is a classifier with high false positive rate undesirable for a cancer detection task?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate for Fitted:  0.000471031559114\n"
     ]
    }
   ],
   "source": [
    "print(\"False Positive Rate for Fitted: \", float(conf_mat[0][1])/(conf_mat[0][1] + conf_mat[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TNR + FPR = 1 for the first part, but there is NO good relation for the FPR and the TPR as they cannot be used to predict each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: ROC Analysis\n",
    "\n",
    "Another powerful diagnostic tool for class-imbalanced classification tasks is the Receiver Operating Characteristic (ROC) curve. Notice that the default logistic regression classifier in `sklearn` classifies a data point by thresholding the predicted class probability $\\hat{P}(Y=1)$ at 0.5. By using a different threshold, we can adjust the trade-off between the true positive rate (TPR) and false positive rate (FPR) of the classifier. The ROC curve allows us to visualize this trade-off across all possible thresholds.\n",
    "\n",
    "\n",
    "1. Display the ROC curve for the fitted classifier on the *test set*. In the same plot, also display the ROC curve for the all 0's classifier. How do the two curves compare?\n",
    "\n",
    "2.  Compute the highest TPR that can be achieved by the classifier at each of the following FPR's, and the thresholds at which they are achieved. Based on your results, comment on how the threshold influences a classifier's FPR.\n",
    "    - FPR = 0\n",
    "    - FPR = 0.1\n",
    "    - FPR = 0.5\n",
    "    - FPR = 0.9\n",
    "- Suppose a clinician told you that diagnosing a cancer patient as normal is *twice* as critical an error as diagnosing a normal patient as having cancer. Based on this information, what threshold would you recommend the clinician to use? What is the TPR and FPR of the classifier at this threshold? \n",
    "\n",
    "- Compute the area under the ROC curve (AUC) for both the fitted classifier and the all 0's classifier. How does the difference in the AUCs of the two classifiers compare with the difference between their classification accuracies in Question 1, Part 2(A)? \n",
    "\n",
    "*Hint:* You may use the `metrics.roc_curve` function to compute the ROC curve for a classification model and the `metrics.roc_auc_score` function to compute the AUC for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 Solutions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1\\. Display the ROC curve for the fitted classifier on the *test set*. In the same plot, also display the ROC curve for the all 0's classifier. How do the two curves compare?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJcAAAJcCAYAAABE9kWlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1290fc0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = logregcv.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, preds)\n",
    "fpr_2, tpr_2, thresholds_2 = metrics.roc_curve(y_test, [0 for y in y_test])\n",
    "roc_auc_2 = metrics.auc(fpr_2, tpr_2)\n",
    "plt.figure(figsize=(20,10))\n",
    "lw = 2\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f) LogReg' % roc_auc)\n",
    "plt.plot([0], [0], marker='o', markersize=10, lw = 0, color=\"red\", label ='ROC curve (area = 0) Naive Classifier')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.02, 1.0])\n",
    "plt.ylim([-0.02, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\", prop={'size':20})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we want the area under the ROC curve to be 1. We would like the curve to rise very fast and to capture as much of the top left area as we can. The ROC curve for all 0's indicates that we are doing no better than random sampling, or tossing a coin. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2\\.  Compute the highest TPR that can be achieved by the classifier at each of the following FPR's, and the thresholds at which they are achieved. Based on your results, comment on how the threshold influences a classifier's FPR.**\n",
    "    - FPR = 0\n",
    "    - FPR = 0.1\n",
    "    - FPR = 0.5\n",
    "    - FPR = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 1.99990555727\n",
      "0.807692307692 0.00571130223307\n",
      "0.961538461538 0.000152201711086\n",
      "0.990384615385 6.32310417421e-09\n"
     ]
    }
   ],
   "source": [
    "print(tpr[np.min([i for i, x in enumerate(fpr) if x>=0])], thresholds[np.min([i for i, x in enumerate(fpr) if x>=0])])\n",
    "print(tpr[np.min([i for i, x in enumerate(fpr) if x>=0.1])], thresholds[np.min([i for i, x in enumerate(fpr) if x>=0.1])])\n",
    "print(tpr[np.min([i for i, x in enumerate(fpr) if x>=0.5])], thresholds[np.min([i for i, x in enumerate(fpr) if x>=0.5])])\n",
    "print(tpr[np.min([i for i, x in enumerate(fpr) if x>=0.9])], thresholds[np.min([i for i, x in enumerate(fpr) if x>=0.9])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our threshold increases, the true positive rate decreases dramatically. As our threshold goes to zero, we will be predicting 1's for everything. As a result, our true positive rate will be very high. As our threshold decreases, the FPR increases, and so does the TPR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3\\. Suppose a clinician told you that diagnosing a cancer patient as normal is *twice* as critical an error as diagnosing a normal patient as having cancer. Based on this information, what threshold would you recommend the clinician to use? What is the TPR and FPR of the classifier at this threshold?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it would be twice as important to increase TPR, we would want a combined metric that weights a higher TPR more. \n",
    "\n",
    "Combined metric = 2*TPR + (1-FPR) and we want to maximize this combined rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_metric  = [2*tpr[i]+(1-fpr[i]) for i in range(len(fpr))]\n",
    "new_metric2 = [(1-tpr[i])-(0.5*fpr[i]) for i in range(len(fpr))]\n",
    "np.argmin(new_metric2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By finding the argmax of the values of our metric, we can compute the threshold as 0.00202226."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0020222606920528977"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds[np.argmax(new_metric)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can find the FPR and the TPR of the classifier at this threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate:  0.884615384615\n",
      "False Positive Rate:  0.196066886481\n"
     ]
    }
   ],
   "source": [
    "print('True Positive Rate: ', tpr[126])\n",
    "print('False Positive Rate: ', fpr[126])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4\\. Compute the area under the ROC curve (AUC) for both the fitted classifier and the all 0's classifier. How does the difference in the AUCs of the two classifiers compare with the difference between their classification accuracies in Question 1, Part 2(A)?** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the ROC Curve for Fitted Classifer:  0.923302814414\n",
      "Area under the ROC Curve for Naive 0 Classifier:  0.5\n"
     ]
    }
   ],
   "source": [
    "print('Area under the ROC Curve for Fitted Classifer: ', roc_auc)\n",
    "print('Area under the ROC Curve for Naive 0 Classifier: ', roc_auc_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The area under the curve is a metric used for classification accuracy. It is a better metric for comparing models in our case. In the logistic regression model, our fitted model had an accuracy score of 0.995084269663 vs. the naive all 0's model of 0.993913857678. In this ROC with the AUC metric approach, we see a much bigger difference from 0.9233028144 to 0.5. Hence, AUC is better able to distinguish between two models based on two metrics alone. The AUC takes into account the true positive and false positive rates as well, instead of just the general accuracy rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 3: Missing data\n",
    "\n",
    "In this problem you are given a different data set, `HW6_dataset_missing.csv`, that is  similar to the one you used above (same column definitions and same conditions), however this data set contains missing values. \n",
    "\n",
    "1. Remove all observations that contain any missing values, split the dataset into a 75-25 train-test split, and fit the regularized logistic regression as in Question 1 (use `LogisticRegressionCV` again to retune).  Report the overall classification rate and TPR in the test set.\n",
    "2. Restart with a fresh copy of the data in `HW6_dataset_missing.csv` and impute the missing data via mean imputation.  Split the data 75-25 and fit the regularized logistic regression model.  Report the overall classification rate and TPR in the test set.  \n",
    "3. Again restart with a fresh copy of the data in `HW6_dataset_missing.csv` and impute the missing data via a model-based imputation method. Once again split the data 75-25 and fit the regularized logistic regression model.  Report the overall classification rate and TPR in the test set.  \n",
    "4. Compare the results in the 3 previous parts of this problem.  Prepare a paragraph (5-6 sentences) discussing the results, the computational complexity of the methods, and conjecture and explain why you get the results that you see.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates the necessary data sets for ALL of the first 3 problems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2_missing = pd.read_csv('HW6_dataset_missing.csv', header=0, names=list(range(1,118)) + ['type'])\n",
    "df2_missing2 = df2_missing.copy()\n",
    "df3_missing3 = df2_missing.copy()\n",
    "\n",
    "# Problem 1 DROP ALL NAN \n",
    "df2_missing.dropna(inplace=True)\n",
    "# SPLIT THE DATA INTO TRAIN/TEST\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(df2_missing)) < 0.75\n",
    "data_train = df2_missing[msk]\n",
    "data_test = df2_missing[~msk]\n",
    "\n",
    "X_train = data_train.loc[:, data_train.columns != 'type']\n",
    "y_train =data_train['type']\n",
    "X_test= data_test.loc[:, data_test.columns != 'type']\n",
    "y_test =data_test['type']\n",
    "# data_train, data_test are for Problem 1\n",
    "\n",
    "# Problem 2 DO NOT DROP BUT IMPUTE WITH MEAN\n",
    "values = df2_missing2.values\n",
    "imputer = Imputer( strategy='mean')\n",
    "df2_missing2 = imputer.fit_transform(values)\n",
    "msk = np.random.rand(len(df2_missing2)) < 0.75\n",
    "data_train2 = df2_missing2[msk]\n",
    "data_test2 = df2_missing2[~msk]\n",
    "\n",
    "X_train2 = data_train2[:, 0:-1]\n",
    "y_train2 =data_train2[:, -1]\n",
    "X_test2 = data_test2[:, 0:-1]\n",
    "y_test2 =data_test2[:, -1]\n",
    "# data_train2, data_test2 are for Problem 2\n",
    "\n",
    "\n",
    "# Problem 3 DO NOT DROP BUT IMPUTE WITH LINEAR REGRESSION\n",
    "cols_full = []\n",
    "cols_missing = []\n",
    "for i in range(df3_missing3.shape[1] - 1):\n",
    "    if sum(df3_missing3.iloc[:, i].isnull()) > 0:\n",
    "        cols_missing.append(i)\n",
    "    else:\n",
    "        cols_full.append(i)\n",
    "\n",
    "full_data_x = df3_missing3.iloc[:, cols_full]\n",
    "full_data_y = df3_missing3['type']\n",
    "\n",
    "for i in cols_missing:\n",
    "\n",
    "    #rows where column i need to be imputed\n",
    "    pred_x = full_data_x[df3_missing3.iloc[:,i].isnull()]\n",
    "\n",
    "    #rows can be used for prediction\n",
    "    reg_x = full_data_x[~df3_missing3.iloc[:,i].isnull()]\n",
    "    reg_y = full_data_y[~df3_missing3.iloc[:,i].isnull()]\n",
    "    \n",
    "    #Linear regression model based on full columns\n",
    "    regress = LinearRegression().fit(reg_x, reg_y)\n",
    "    reg_y_hat = regress.predict(reg_x)\n",
    "    y_hat = regress.predict(pred_x)\n",
    "    y_hat_noise = y_hat + np.random.normal(loc=0, scale = np.sqrt(mean_squared_error(reg_y, reg_y_hat)), size = y_hat.shape[0])\n",
    "    \n",
    "    missing_series = pd.Series(data=y_hat_noise, index=df3_missing3.iloc[:,i][df3_missing3.iloc[:,i].isnull()].index)\n",
    "    df3_missing3.iloc[:,i] = df3_missing3.iloc[:,i].fillna(missing_series)\n",
    "\n",
    "msk = np.random.rand(len(df3_missing3)) < 0.75\n",
    "data_train3 = df3_missing3[msk]\n",
    "data_test3 = df3_missing3[~msk]\n",
    "\n",
    "X_train3 = data_train3.loc[:, data_train3.columns != 'type']\n",
    "y_train3 =data_train3['type']\n",
    "X_test3= data_test3.loc[:, data_test3.columns != 'type']\n",
    "y_test3 =data_test3['type']\n",
    "# data_train3, data_test3 are for Problem 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1\\. Remove all observations that contain any missing values, split the dataset into a 75-25 train-test split, and fit the regularized logistic regression as in Question 1 (use `LogisticRegressionCV` again to retune).  Report the overall classification rate and TPR in the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy for Problem 1:  0.999074074074\n",
      "Test accuracy for Problem 1:  0.994382022472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "# Problem 1\n",
    "logregcv = LogisticRegressionCV()\n",
    "logregcv.fit(X_train, y_train)\n",
    "y_hat_train = logregcv.predict(X_train)\n",
    "y_hat_test = logregcv.predict(X_test)\n",
    "print(\"Train accuracy for Problem 1: \", accuracy_score(y_train, y_hat_train))\n",
    "print(\"Test accuracy for Problem 1: \", accuracy_score(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat=0</th>\n",
       "      <th>y_hat = 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y=0</th>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y=1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_hat=0  y_hat = 1\n",
       "y=0      354          0\n",
       "y=1        2          0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem 1 \n",
    "conf_mat_1 = confusion_matrix(y_test, y_hat_test)\n",
    "conf_df_1 = pd.DataFrame(conf_mat_1, columns = ['y_hat=0', 'y_hat = 1'], index = ['y=0', 'y=1'])\n",
    "conf_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate for Part 1:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"True Positive Rate for Part 1: \", float(conf_mat_1[1][1])/(conf_mat_1[1][1]+ conf_mat_1[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2\\. Restart with a fresh copy of the data in `HW6_dataset_missing.csv` and impute the missing data via mean imputation.  Split the data 75-25 and fit the regularized logistic regression model.  Report the overall classification rate and TPR in the test set.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy for Problem 2:  0.994751908397\n",
      "test accuracy for Problem 2:  0.99511002445\n"
     ]
    }
   ],
   "source": [
    "logregcv = LogisticRegressionCV()\n",
    "logregcv.fit(X_train2, y_train2)\n",
    "y_hat_train2 = logregcv.predict(X_train2)\n",
    "y_hat_test2 = logregcv.predict(X_test2)\n",
    "print(\"train accuracy for Problem 2: \", accuracy_score(y_train2, y_hat_train2))\n",
    "print(\"test accuracy for Problem 2: \", accuracy_score(y_test2, y_hat_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create the confusion matrix for Problem 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat=0</th>\n",
       "      <th>y_hat = 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y=0</th>\n",
       "      <td>6102</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y=1</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_hat=0  y_hat = 1\n",
       "y=0     6102          2\n",
       "y=1       28          3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem 2\n",
    "conf_mat_2 = confusion_matrix(y_test2, y_hat_test2)\n",
    "conf_df_2 = pd.DataFrame(conf_mat_2, columns = ['y_hat=0', 'y_hat = 1'], index = ['y=0', 'y=1'])\n",
    "conf_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate for Part 2:  0.0967741935484\n"
     ]
    }
   ],
   "source": [
    "print(\"True Positive Rate for Part 2: \", float(conf_mat_2[1][1])/(conf_mat_2[1][1]+ conf_mat_2[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3\\. Again restart with a fresh copy of the data in `HW6_dataset_missing.csv` and impute the missing data via a model-based imputation method. Once again split the data 75-25 and fit the regularized logistic regression model.  Report the overall classification rate and TPR in the test set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy for Problem 3:  0.994414596521\n",
      "test accuracy for Problem 3:  0.996129032258\n"
     ]
    }
   ],
   "source": [
    "logregcv = LogisticRegressionCV()\n",
    "logregcv.fit(X_train3, y_train3)\n",
    "y_hat_train3 = logregcv.predict(X_train3)\n",
    "y_hat_test3 = logregcv.predict(X_test3)\n",
    "print(\"train accuracy for Problem 3: \", accuracy_score(y_train3, y_hat_train3))\n",
    "print(\"test accuracy for Problem 3: \", accuracy_score(y_test3, y_hat_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat=0</th>\n",
       "      <th>y_hat = 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y=0</th>\n",
       "      <td>6168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y=1</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_hat=0  y_hat = 1\n",
       "y=0     6168          1\n",
       "y=1       23          8"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_3 = confusion_matrix(y_test3, y_hat_test3)\n",
    "conf_df_3 = pd.DataFrame(conf_mat_3, columns = ['y_hat=0', 'y_hat = 1'], index = ['y=0', 'y=1'])\n",
    "conf_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate for Part 3:  0.258064516129\n"
     ]
    }
   ],
   "source": [
    "print(\"True Positive Rate for Part 3: \", float(conf_mat_3[1][1])/(conf_mat_3[1][1]+ conf_mat_3[1][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4\\. Compare the results in the 3 previous parts of this problem.  Prepare a paragraph (5-6 sentences) discussing the results, the computational complexity of the methods, and conjecture and explain why you get the results that you see.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result with dropping all NA values results in the lowest TPR, with the mean method giving the second best TPR result, and finally, the imputation method with Linear Regression yields the best. The computational complexity of the linear regression model is the highest, as we need to fit a model for each NA value, while in the mean method it was just computing a mean across values. The NA method is the lowest complexity as it just involves dropping values. \n",
    "\n",
    "We expect to see the higher TPR from Imputation using Linear regression model since it provides a more sophisticated prediction for the missing values, rather than taking the mean out of all existing values. Due to the imbalance of 0 and 1's, linear regression is able to better account for this than the simple mean method. The simple mean method takes the same value of the mean over the number of entries in a column, while linear regression does a weighting over it instead, allow us to have better predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 209 Question\n",
    "This problem walks you through the derivation of the **likelihood equations** for a generalized linear model (GLM). Suppose that the random component of the GLM is in the univariate natural exponential family, so that\n",
    "$$f(y_i|\\theta_i) = h(y_i) e^{y_i\\theta_i - b(\\theta_i)}$$\n",
    "Define the individual log-likelihood for each observation $i$ as\n",
    "$$l_i(\\theta_i) \\equiv \\log f(y_i|\\theta_i)$$\n",
    "with linear predictor\n",
    "$$\\eta_i = x_i^T\\beta = g(\\mu_i)$$\n",
    "for some link function $g$, and\n",
    "$$\\mu_i = E[y_i|\\theta_i]$$\n",
    "is the mean of each observation.\n",
    "\n",
    "\n",
    "1.Use the above expressions to write a simplified expression for the log-likelihood $l(\\theta)$ for the entire dataset, $y_1, \\dots, y_n$.\n",
    "\n",
    "Solution: We can take the sum of the individual log-likelihoods to find that\n",
    "$$l(\\theta) = \\sum_i \\log f(y_i|\\theta_i) = \\sum_i \\log h(y_i) + \\sum_i y_i \\theta_i - \\sum_i b(\\theta_i)$$\n",
    "\n",
    "2.Use the chain rule to express $\\frac{\\partial l_i}{\\partial \\beta_j}$ in terms of the derivatives of $l_i, \\theta_i, \\mu_i$, and $\\eta_i$. (\\emph{Hint}: Think carefully about which variables are related to which, and in what way. For example, for which of the above variables do you know the derivative with respect to $\\beta_j$?)\n",
    "\n",
    "Solution: Note that $l_i$ is written in terms of $\\theta_i$. Then $\\theta_i$ is related to $\\mu_i$ via $\\mu_i = b'(\\theta_i)$. Next, $\\mu_i$ is related to $\\eta_i$ via the link function, and $\\eta_i$ is related to $\\beta_j$ via the linear predictor. Thus,\n",
    "$$\\frac{\\partial l_i}{\\partial \\beta_j} = \\frac{\\partial l_i}{\\partial \\theta_i} \\frac{\\partial \\theta_i}{\\partial \\mu_i} \\frac{\\partial \\mu_i}{\\partial \\eta_i} \\frac{\\partial \\eta_i}{\\partial \\beta_j}$$\n",
    "\n",
    "3.Compute the derivatives for $\\frac{\\partial l_i}{\\partial \\theta_i}$ and $\\frac{\\partial \\eta_i}{\\partial \\beta_j}$.\n",
    "\n",
    "Solution: From our solution to part 1, we see that\n",
    "$$\\frac{\\partial l_i}{\\partial \\theta_i} = y_i - b'(\\theta_i) = y_i - \\mu_i$$\n",
    "and from the linear predictor, we see that\n",
    "$$\\frac{\\partial \\eta_i}{\\partial \\beta_j} = x_{ij}$$\n",
    "\n",
    "4.Express $\\mu_i$ in terms of $\\theta_i$, and use this relationship to compute $\\frac{\\partial \\theta_i}{\\partial \\mu_i}$. (_Hint_: Recall the cumulant function of a natural exponential family, and assume that you can write $\\partial f/\\partial g = (\\partial g / \\partial f)^{-1}$.)\n",
    "\n",
    "Solution: Again, note that $\\mu_i = b'(\\theta_i)$, and so\n",
    "$$\\frac{\\partial \\theta_i}{\\partial \\mu_i} = \\left(\\frac{\\partial \\mu_i}{\\partial \\theta_i}\\right)^{-1} = (b''(\\theta_i))^{-1} = (var(y_i))^{-1}$$\n",
    "\n",
    "5.Express $\\eta_i$ in terms of $\\mu_i$. Using the same hint as the above, compute $\\frac{\\partial \\mu_i}{\\partial \\eta_i}$.\n",
    "\n",
    "Solution: Note that $g(\\mu_i) =\\eta_i$, and so\n",
    "$$\\frac{\\partial \\mu_i}{\\partial \\eta_i} = \\left(\\frac{\\partial \\eta_i}{\\partial \\mu_i}\\right) = (g'(\\mu_i))^{-1}$$\n",
    "\n",
    "6.Put all of the above parts together to write an expression for $\\frac{\\partial l}{\\partial \\beta_j}$. Use matrix notation to write this expression as\n",
    "$$\\nabla_{\\beta} l(\\beta) = X^TDV^{-1}(Y - \\mu) = 0$$\n",
    "That is, compute the matrices $D$ and $V$ such that this equation holds.\n",
    "\n",
    "Solution: Plugging in the solutions from parts 3-5 into part 2, we have\n",
    "$$\\frac{\\partial l_i}{\\partial \\beta_j} = \\frac{(y_i-\\mu_i)x_{ij}}{var(y_i)g'(\\mu_i)}$$\n",
    "Thus,\n",
    "$$\\frac{\\partial l}{\\partial \\beta_j} = \\sum_i \\frac{(y_i-\\mu_i)x_{ij}}{var(y_i)g'(\\mu_i)}$$\n",
    "which can be written in the above matrix form using\n",
    "$$D = \\text{diag}(g'(\\mu_i)^{-1})$$\n",
    "$$V = \\text{diag}(var(y_i))$$\n",
    "\n",
    "7.If we use the canonical link function, how do your answers to part (6) simplify?\n",
    "\n",
    "Solution: Note that for canonical link functions, $\\theta_i = \\eta_i$, and so the derivative becomes\n",
    "$$\\frac{\\partial l_i}{\\partial \\beta_j} = \\frac{\\partial l_i}{\\partial \\eta_i}\\frac{\\partial \\eta_i}{\\partial \\beta_j} = (y_i-\\mu_i) x_{ij}$$\n",
    "Thus, the matrix equation is simply\n",
    "$$\\nabla_{\\beta} l(\\beta) = X^T(Y - \\mu) = 0$$\n",
    "\n",
    "8.Finally, compute the above likelihood equations in the case of logistic regression, and show that this is equivalent to the solution given in lecture.\n",
    "\n",
    "Solution: Note that for logistic regression, we do use the canonical link, so from part 7, we see that this is simply\n",
    "$$X^T [Y - logit^{-1}(X\\beta)] = 0$$\n",
    "To show that this is completely equivalent to the likelihood approach from lecture, which it must be since both are simply taking first-order conditions of the likelihood,note that the log-likelihood of logistic regression can be written as\n",
    "$$l(\\beta) \\equiv \\sum_i [y_i \\log(logit^{-1}(x_i^T\\beta)) +(1-y_i) \\log (1-logit^{-1}(x_i^T\\beta)]$$\n",
    "$$= \\sum_i \\left[ y_i \\log \\left( \\frac{logit^{-1}(x_i^T\\beta)}{1 - logit^{-1}(x_i^T\\beta)}\\right) + \\log(1-logit^{-1}(x_i^T\\beta)\\right]$$\n",
    "$$ = \\sum_i [y_i x_i^T\\beta + \\log (1-logit^{-1}(x_i^T\\beta)]$$\n",
    "noting that the first term is a logit; and taking partial derivatives, we find\n",
    "$$\\frac{\\partial l}{\\partial \\beta_j} = \\sum_i y_i x_{ij} - \\sum_i logit^{-1}(x_i^T\\beta)x_{ij}$$\n",
    "The derivative of the second term is quite simple if you recall from section that $\\partial_x logit^{-1}(x) = logit^{-1}(x) (1-logit^{-1}(x))$.\n",
    "\n",
    "Thus, this can clearly be written in matrix form as\n",
    "$$X^TY = X^Tlogit^{-1}(X\\beta)$$\n",
    "which is identical to the above."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
